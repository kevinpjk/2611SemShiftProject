{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SemEval2020 Task 1 Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 1: Train two models for two time points and align them using Orthogonal Procrustes\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "\n",
    "# Training word2vec model on english practice corpus 1\n",
    "model = Word2Vec(corpus_file=\"trial_data_public/corpora/english/corpus1/corpus1.txt\", vector_size=300, window=10, min_count=1, workers=4, negative=5)\n",
    "# model.save(\"eng_prac_corp1.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Saving wordvectors\n",
    "word_vectors = model.wv\n",
    "word_vectors.save(\"eng_prac_corp1.wordvectors\")\n",
    "\n",
    "wv = KeyedVectors.load(\"eng_prac_corp1.wordvectors\", mmap='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('after', 0.9997694492340088), ('into', 0.9997608661651611), ('over', 0.9997478127479553), ('through', 0.9997445344924927), ('stand', 0.9997408390045166), ('eye', 0.9997376203536987), ('first', 0.9997310042381287), ('while', 0.9997270107269287), ('both', 0.9997267127037048), ('light', 0.9997245073318481)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar('walk', topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store target words\n",
    "target_words = ['walk', 'distance', 'small', 'god']\n",
    "\n",
    "with open(\"trial_data_public/corpora/english/corpus2/corpus2.txt\") as file:\n",
    "    lines = [line.rstrip().split() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train second word2vec model using corpus2 lines\n",
    "model2 = Word2Vec(lines, vector_size=300, window=10, min_count=1, workers=4, negative=5)\n",
    "# Saving wordvectors\n",
    "word_vectors2 = model2.wv\n",
    "word_vectors2.save(\"eng_prac_corp2.wordvectors\")\n",
    "\n",
    "wv2 = KeyedVectors.load(\"eng_prac_corp2.wordvectors\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('out', 0.999792218208313), ('into', 0.999790370464325), ('off', 0.9997903108596802), ('their', 0.9997901916503906), ('her', 0.9997893571853638), ('and', 0.9997891783714294), (\"'s\", 0.9997891187667847), ('make', 0.9997890591621399), ('down', 0.9997889995574951), ('from', 0.9997884035110474)]\n"
     ]
    }
   ],
   "source": [
    "print(model2.wv.most_similar('walk', topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walk [[0.9994904]]\n",
      "distance [[0.9996628]]\n",
      "small [[0.999903]]\n",
      "god [[0.9994504]]\n"
     ]
    }
   ],
   "source": [
    "# Align wv and wv2 using Orthogonal Procrustes\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# print(wv.get_normed_vectors(), wv2.get_normed_vectors())\n",
    "\n",
    "# Get vectors for target words\n",
    "wv_target_vectors = np.array([wv.get_vector(word) for word in target_words])\n",
    "wv2_target_vectors = np.array([wv2.get_vector(word) for word in target_words])\n",
    "\n",
    "wv_target_vectors_mu = wv_target_vectors.mean(axis=0)\n",
    "wv_target_vectors_centered = wv_target_vectors - wv_target_vectors_mu\n",
    "\n",
    "wv2_target_vectors_mu = wv2_target_vectors.mean(axis=0)\n",
    "wv2_target_vectors_centered = wv2_target_vectors - wv2_target_vectors_mu\n",
    "\n",
    "R, sca = orthogonal_procrustes(wv_target_vectors_centered, wv2_target_vectors_centered)\n",
    "# print(R, sca)\n",
    "scale = sca / np.square(norm(wv_target_vectors_centered))\n",
    "\n",
    "wv2_target_vectors_approx = scale * np.dot(wv_target_vectors_centered, R) + wv2_target_vectors_mu\n",
    "\n",
    "# Now we have the aligned vectors for target words in wv2_target_vectors_approx\n",
    "# We can use these vectors to find the most similar words in wv2\n",
    "for i, word in enumerate(target_words):\n",
    "    print(word, cosine_similarity(wv2_target_vectors_approx[i].reshape(1,-1), wv2_target_vectors[i].reshape(1,-1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gay ['the', 'same', 'mansion', 'rouse', 'by', 'the', 'same', 'cheer', 'note', 'but', 'he', 'smile', 'not', 'upon', 'the', 'joyous', 'throng', 'as', 'they', 'gather', 'around', 'the', 'spot', 'occupy', 'by', 'congo', 'and', 'his', 'canine', 'favourite', 'nor', 'yet', 'upon', 'those', 'of', 'the', 'gay', 'youth', 'who', 'ride', 'up', 'and', 'touch', 'their', 'beaver', 'respectfully', 'to', 'the', 'smiling', 'maiden', 'as', 'they', 'singly', 'or', 'in', 'pair', 'canter', 'away', 'over', 'the', 'bridge', 'in', 'pursuit', 'of', 'their', 'day', \"'s\", 'sport']\n",
      "gay ['what', 'poor', 'little', 'blind', 'alice', 'discern', 'in', 'him', 'and', 'love', 'the', 'gay', 'young', 'lady', 'can', 'not', 'see']\n",
      "gay ['it', 'be', 'early', 'in', 'the', 'month', 'of', 'july', 'the', 'earth', 'gay', 'in', 'its', 'green', 'pomp', 'of', 'foliage', 'its', 'rich', 'flush', 'of', 'bloom', 'the', 'heaven', 'dazzlingly', 'blue', 'the', 'air', 'mild', 'and', 'balmy', 'the', 'wild', 'landscape', 'diversify', 'with', 'its', 'laugh', 'wineyards', 'its', 'white', 'hamlet', 'its', 'shadowy', 'forest', 'the', 'silvery', 'line', 'of', 'the', 'river', 'vele', 'flash', 'and', 'sparkle', 'in', 'sunshine', 'and', 'the', 'gray']\n",
      "gay ['among', 'these', 'our', 'heroine', 'awaken', 'by', 'the', 'echo', 'chorus', 'of', 'the', 'hunter', \"'s\", 'horn', 'be', 'already', 'dress', 'and', 'smile', 'from', 'her', 'window', 'like', 'one', 'of', 'her', 'own', 'sweet', 'flower', 'upon', 'the', 'gay', 'young', 'cavalier', 'as', 'they', 'pass', 'in', 'review', 'before']\n",
      "gay ['the', 'young', 'only', 'be', 'thoroughly', 'gay', 'here']\n",
      "gay ['i', 'know', 'sally', 'wilton', 'be', 'a', 'gay', 'thoughtless', 'thing', 'but', 'so', 'be', 'most', 'girl', 'and', 'i', 'believe', 'that', 'when', 'she', 'be']\n",
      "gay ['a', 'dancing', 'shape', 'an', 'image', 'gay', 'to', 'haunt', 'to', 'startle', 'and', 'waylay']\n",
      "gay ['golden', 'hour', 'of', 'pleasure', 'that', 'rejoice', 'the', 'gay', 'and', 'merry', 'and', 'while', 'he', 'wait', 'at', 'the', 'portal', 'of', 'pleasure', 'or', 'step', 'into', 'the', 'porch', 'of', 'affliction', 'his', 'opportunity', 'glide', 'silently', 'and', 'unmarked', 'forever', 'away']\n",
      "gay_ ['to', 'this', 'left', 'syndrome', 'democratic', 'as', 'well', 'as', 'republican', 'opponent', 'of', 'mcgovern', 'radical', 'want', 'to', 'add', 'abortion', 'gay_', 'right', 'among', 'other', 'goad', 'to', 'white', 'middleclass', 'and', 'blue-collar', 'voter']\n",
      "gay_ ['gay_', 'return', 'the', 'kick-off', 'to', 'the', 'trojan', '13', 'and', 'after', 'a', 'bitterly', 'contest', 'trojan', 'penalty', 'for', 'pass', 'interference', 'the', 'irish', 'score', 'from', 'the', 'new', 'line', 'of', 'scrimmage', 'only', 'two', 'yard', 'shy', 'of', 'the', 'goal']\n",
      "gay_ ['and', 'that', 'francisco', 'caldera', 'be', 'a', 'gay_', 'man', 'also']\n",
      "0.0056795477867126465\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Approach 2: Train a combined model on both corpora (target words in corpus2 are changed to target_word_)\n",
    "target_words = ['walk', 'distance', 'small', 'god', 'gay']\n",
    "\n",
    "# Store corpus1 and corpus2 lines together\n",
    "c1_c2_lines = []\n",
    "\n",
    "with open(\"trial_data_public/corpora/english/corpus1/corpus1.txt\") as file:\n",
    "    c1_lines = [line.rstrip().split() for line in file]\n",
    "    c1_c2_lines.extend(c1_lines)\n",
    "\n",
    "with open(\"trial_data_public/corpora/english/corpus2/corpus2.txt\") as file:\n",
    "    c2_lines = [line.rstrip().split() for line in file]\n",
    "    for line in c2_lines:\n",
    "        for word in line:\n",
    "            if word in target_words:\n",
    "                line[line.index(word)] = word + '_'\n",
    "    c1_c2_lines.extend(c2_lines)\n",
    "\n",
    "for line in c1_c2_lines:\n",
    "    if 'gay_' in line:\n",
    "        print('gay_', line)\n",
    "    if 'gay' in line:\n",
    "        print('gay', line)\n",
    "\n",
    "# Train combined model\n",
    "model_combined = Word2Vec(c1_c2_lines, vector_size=300, window=10, min_count=1, workers=4, negative=5)\n",
    "# Saving wordvectors\n",
    "word_vectors_combined = model_combined.wv\n",
    "word_vectors_combined.save(\"eng_prac_combined.wordvectors\")\n",
    "\n",
    "wv_combined = KeyedVectors.load(\"eng_prac_combined.wordvectors\", mmap='r')\n",
    "\n",
    "print(wv_combined.distance('gay', 'gay_'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation using DatSemShift 3.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['5548', 'pope', '→', 'ruff (fish)'], ['6550', '<hat>', '→', 'mushroom cap'], ['0750', 'to search, to look for', '↔', 'to want']]\n"
     ]
    }
   ],
   "source": [
    "############################## EVALUATION USING DATSEMSHIFT 3.0 #######################################\n",
    "\n",
    "# Open semShift.txt file\n",
    "with open(\"../semShift.txt\") as file:\n",
    "    # Split the lines of the file by tabs\n",
    "    lines = [line.rstrip().split('\\t') for line in file]\n",
    "\n",
    "# lines is the first four strings of each line\n",
    "lines = [line[:4] for line in lines]\n",
    "print(lines[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word1</th>\n",
       "      <th>shift_dir</th>\n",
       "      <th>word2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5548</td>\n",
       "      <td>pope</td>\n",
       "      <td>→</td>\n",
       "      <td>ruff (fish)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6550</td>\n",
       "      <td>&lt;hat&gt;</td>\n",
       "      <td>→</td>\n",
       "      <td>mushroom cap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>750</td>\n",
       "      <td>to search, to look for</td>\n",
       "      <td>↔</td>\n",
       "      <td>to want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4864</td>\n",
       "      <td>heart</td>\n",
       "      <td>→</td>\n",
       "      <td>hearts (in cards)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6858</td>\n",
       "      <td>&lt;country&gt;</td>\n",
       "      <td>→</td>\n",
       "      <td>turkey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                   word1 shift_dir              word2\n",
       "0  5548                    pope         →        ruff (fish)\n",
       "1  6550                   <hat>         →       mushroom cap\n",
       "2   750  to search, to look for         ↔            to want\n",
       "3  4864                   heart         →  hearts (in cards)\n",
       "4  6858               <country>         →             turkey"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load DatSemShift dataset in pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../semShift.csv', header=None)\n",
    "df.columns = ['id', 'word1', 'shift_dir', 'word2']\n",
    "df.head()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
